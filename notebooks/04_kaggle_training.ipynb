{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸ”¥ IEEE-CIS Fraud Detection â€” Model Training\n",
                "\n",
                "Full pipeline: Load â†’ Preprocess â†’ Feature Engineer â†’ Train (LGB/XGB/CAT) â†’ Evaluate\n",
                "\n",
                "### Data Sources Added\n",
                "| Dataset | Kaggle slug |\n",
                "|---------|-------------|\n",
                "| IEEE fraud data | `muhakabartay/yourallmodelsdata` |\n",
                "| Source code | `aryyaaaaa/fraud-detection-src` |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "import os, sys, shutil, gc, time, warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "import numpy as np, pandas as pd\n",
                "import matplotlib.pyplot as plt, seaborn as sns\n",
                "import logging\n",
                "\n",
                "logging.basicConfig(level=logging.INFO, format='%(message)s')\n",
                "\n",
                "# Matplotlib style â€” fall back gracefully\n",
                "try:\n",
                "    plt.style.use('seaborn-v0_8-whitegrid')\n",
                "except OSError:\n",
                "    plt.style.use('seaborn-whitegrid')\n",
                "plt.rcParams.update({'figure.figsize': [14, 6], 'figure.dpi': 110})\n",
                "\n",
                "OUT = '/kaggle/working'\n",
                "\n",
                "# â”€â”€ AUTO-DETECT DATA PATH â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
                "DATA_CANDIDATES = [\n",
                "    '/kaggle/input/yourallmodelsdata',\n",
                "    '/kaggle/input/datasets/muhakabartay/yourallmodelsdata',\n",
                "]\n",
                "INPUT = None\n",
                "for p in DATA_CANDIDATES:\n",
                "    if os.path.isdir(p):\n",
                "        INPUT = p\n",
                "        break\n",
                "if INPUT is None:\n",
                "    for d in os.listdir('/kaggle/input'):\n",
                "        full = f'/kaggle/input/{d}'\n",
                "        if os.path.isdir(full) and os.path.exists(f'{full}/train_transaction.csv'):\n",
                "            INPUT = full\n",
                "            break\n",
                "assert INPUT is not None, (\n",
                "    'Could not find train_transaction.csv. '\n",
                "    'Add the IEEE-CIS dataset via \\\"Add Data\\\".'\n",
                ")\n",
                "print(f'âœ… Data path: {INPUT}')\n",
                "print(f'   Files: {os.listdir(INPUT)}')\n",
                "\n",
                "# â”€â”€ AUTO-DETECT SRC PATH â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
                "SRC_CANDIDATES = [\n",
                "    '/kaggle/input/fraud-detection-src',\n",
                "    '/kaggle/input/datasets/aryyaaaaa/fraud-detection-src',\n",
                "]\n",
                "SRC_INPUT = None\n",
                "for p in SRC_CANDIDATES:\n",
                "    if os.path.isdir(p):\n",
                "        SRC_INPUT = p\n",
                "        break\n",
                "if SRC_INPUT is None:\n",
                "    for d in os.listdir('/kaggle/input'):\n",
                "        full = f'/kaggle/input/{d}'\n",
                "        # Look for a directory that contains src/ or data/ subpackage\n",
                "        if os.path.isdir(full) and (\n",
                "            os.path.isdir(f'{full}/src') or os.path.isdir(f'{full}/data')\n",
                "        ):\n",
                "            if full != INPUT:  # Don't confuse with the data dataset\n",
                "                SRC_INPUT = full\n",
                "                break\n",
                "assert SRC_INPUT is not None, (\n",
                "    'Could not find src modules. '\n",
                "    'Add the fraud-detection-src dataset via \\\"Add Data\\\".'\n",
                ")\n",
                "print(f'âœ… Src  path: {SRC_INPUT}')\n",
                "print(f'   Contents: {os.listdir(SRC_INPUT)}')\n",
                "\n",
                "# â”€â”€ Copy src/ into /kaggle/working for imports â”€â”€â”€â”€\n",
                "dst = f'{OUT}/src'\n",
                "if os.path.exists(dst):\n",
                "    shutil.rmtree(dst)\n",
                "\n",
                "if os.path.isdir(f'{SRC_INPUT}/src'):\n",
                "    shutil.copytree(f'{SRC_INPUT}/src', dst)\n",
                "    print(f'âœ… Copied {SRC_INPUT}/src â†’ {dst}')\n",
                "elif os.path.isdir(f'{SRC_INPUT}/data') and os.path.isdir(f'{SRC_INPUT}/features'):\n",
                "    # The dataset root IS the src package contents\n",
                "    shutil.copytree(SRC_INPUT, dst)\n",
                "    print(f'âœ… Copied {SRC_INPUT} (root) â†’ {dst}')\n",
                "else:\n",
                "    raise FileNotFoundError(\n",
                "        f'Cannot find src/ inside {SRC_INPUT}. '\n",
                "        f'Contents: {os.listdir(SRC_INPUT)}'\n",
                "    )\n",
                "\n",
                "sys.path.insert(0, OUT)\n",
                "\n",
                "# Quick smoke-test import\n",
                "from src.data.preprocessor import DataPreprocessor\n",
                "print(f'âœ… Import smoke-test passed')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "!pip install -q lightgbm xgboost catboost 2>/dev/null\n",
                "print('âœ… Dependencies ready')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 1 Â· Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "t0 = time.time()\n",
                "print('Loading train_transaction.csv â€¦')\n",
                "train_txn = pd.read_csv(f'{INPUT}/train_transaction.csv')\n",
                "print(f'  â†’ {len(train_txn):,} rows')\n",
                "\n",
                "print('Loading train_identity.csv â€¦')\n",
                "train_id = pd.read_csv(f'{INPUT}/train_identity.csv')\n",
                "print(f'  â†’ {len(train_id):,} rows')\n",
                "\n",
                "print('Merging â€¦')\n",
                "df = train_txn.merge(train_id, on='TransactionID', how='left')\n",
                "del train_txn, train_id; gc.collect()\n",
                "\n",
                "print(f'\\nðŸ“¦ Shape: {df.shape}  Fraud: {df.isFraud.mean():.4%}  '\n",
                "      f'Mem: {df.memory_usage(deep=True).sum()/1e9:.2f} GB  '\n",
                "      f'Time: {time.time()-t0:.0f}s')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 2 Â· Preprocess"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "from src.data.preprocessor import DataPreprocessor\n",
                "\n",
                "preprocessor = DataPreprocessor()\n",
                "t0 = time.time()\n",
                "\n",
                "print('Cleaning â€¦')\n",
                "df_clean = preprocessor.clean_data(df)\n",
                "del df; gc.collect()\n",
                "\n",
                "print('Splitting (time-based) â€¦')\n",
                "train_df, val_df, test_df = preprocessor.time_based_split(df_clean)\n",
                "del df_clean; gc.collect()\n",
                "\n",
                "for name, d in [('Train', train_df), ('Val', val_df), ('Test', test_df)]:\n",
                "    print(f'  {name:5s}: {len(d):>8,}  fraud={d.isFraud.mean():.4%}')\n",
                "print(f'â± {time.time()-t0:.0f}s')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 3 Â· Feature Engineering"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "from src.features.engineer import FraudFeatureEngineer\n",
                "\n",
                "engineer = FraudFeatureEngineer(lookback_windows=[1, 7, 30])\n",
                "t0 = time.time()\n",
                "\n",
                "print('Train features â€¦')\n",
                "train_feat = engineer.fit_transform(train_df, train_df=train_df)\n",
                "print(f'  â†’ {train_feat.shape}')\n",
                "\n",
                "print('Val features â€¦')\n",
                "val_feat = engineer.fit_transform(val_df, train_df=train_df)\n",
                "print(f'  â†’ {val_feat.shape}')\n",
                "\n",
                "print('Test features â€¦')\n",
                "test_feat = engineer.fit_transform(test_df, train_df=train_df)\n",
                "print(f'  â†’ {test_feat.shape}')\n",
                "\n",
                "del train_df, val_df, test_df; gc.collect()\n",
                "print(f'\\nâœ… Done in {time.time()-t0:.0f}s  Features: {train_feat.shape[1]}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# Build X/y â€” keep only numeric features\n",
                "EXCLUDE = {'TransactionID', 'isFraud', 'TransactionDT',\n",
                "           'transaction_datetime', 'FraudLabel', 'datetime',\n",
                "           'card1', 'card2'}\n",
                "\n",
                "NUMERIC_DTYPES = {'int64','float64','int32','float32','int16','float16','uint8'}\n",
                "\n",
                "feat_cols = [c for c in train_feat.columns\n",
                "             if c not in EXCLUDE\n",
                "             and str(train_feat[c].dtype) in NUMERIC_DTYPES]\n",
                "\n",
                "# Ensure val/test have same columns (drop any that don't exist)\n",
                "feat_cols = [c for c in feat_cols\n",
                "             if c in val_feat.columns and c in test_feat.columns]\n",
                "\n",
                "X_train = train_feat[feat_cols].fillna(-999).astype('float32')\n",
                "y_train = train_feat['isFraud'].values\n",
                "\n",
                "X_val = val_feat[feat_cols].fillna(-999).astype('float32')\n",
                "y_val = val_feat['isFraud'].values\n",
                "\n",
                "X_test = test_feat[feat_cols].fillna(-999).astype('float32')\n",
                "y_test = test_feat['isFraud'].values\n",
                "\n",
                "del train_feat, val_feat, test_feat; gc.collect()\n",
                "print(f'Features: {len(feat_cols)}  X_train: {X_train.shape}  '\n",
                "      f'Mem: {X_train.memory_usage(deep=True).sum()/1e9:.2f} GB')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 4 Â· Train LightGBM"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "from src.models.lightgbm_model import LightGBMFraudDetector\n",
                "\n",
                "lgb_m = LightGBMFraudDetector()\n",
                "t0 = time.time()\n",
                "lgb_r = lgb_m.train(X_train, y_train, X_val, y_val,\n",
                "                    num_boost_round=1000, early_stopping_rounds=50)\n",
                "print(f'â± {time.time()-t0:.0f}s')\n",
                "lgb_m.save(f'{OUT}/lightgbm_detector.pkl')\n",
                "print('ðŸ’¾ Saved')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5 Â· Train XGBoost"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "from src.models.xgboost_model import XGBoostFraudDetector\n",
                "\n",
                "xgb_m = XGBoostFraudDetector()\n",
                "t0 = time.time()\n",
                "xgb_r = xgb_m.train(X_train, y_train, X_val, y_val,\n",
                "                    num_boost_round=1000, early_stopping_rounds=50)\n",
                "print(f'â± {time.time()-t0:.0f}s')\n",
                "xgb_m.save(f'{OUT}/xgboost_detector.pkl')\n",
                "print('ðŸ’¾ Saved')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6 Â· Train CatBoost"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "from src.models.catboost_model import CatBoostFraudDetector\n",
                "\n",
                "cat_m = CatBoostFraudDetector()\n",
                "cat_m.params['iterations'] = 1000\n",
                "cat_m.params['verbose'] = 100\n",
                "t0 = time.time()\n",
                "cat_r = cat_m.train(X_train, y_train, X_val, y_val)\n",
                "print(f'â± {time.time()-t0:.0f}s')\n",
                "cat_m.save(f'{OUT}/catboost_detector.cbm')\n",
                "print('ðŸ’¾ Saved')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 7 Â· Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "from src.evaluation.metrics import evaluate_fraud_model, compare_models, find_optimal_threshold\n",
                "\n",
                "lgb_p = lgb_m.predict(X_test)\n",
                "xgb_p = xgb_m.predict(X_test)\n",
                "cat_p = cat_m.predict(X_test)\n",
                "\n",
                "preds = {'LightGBM': lgb_p, 'XGBoost': xgb_p, 'CatBoost': cat_p}\n",
                "comp = compare_models(y_test, preds)\n",
                "\n",
                "print('\\n' + '='*60)\n",
                "print('  MODEL COMPARISON (Test Set)')\n",
                "print('='*60)\n",
                "print(comp.to_string(index=False))\n",
                "print('='*60)\n",
                "comp.to_csv(f'{OUT}/model_comparison.csv', index=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# Best model details\n",
                "best = comp.iloc[0]['Model']\n",
                "print(f'\\nðŸ† Best model: {best}\\n')\n",
                "_ = evaluate_fraud_model(y_test, preds[best])\n",
                "\n",
                "# find_optimal_threshold returns (threshold, metrics_dict)\n",
                "opt_thresh, opt_metrics = find_optimal_threshold(y_test, preds[best], metric='f1')\n",
                "print(f'\\nOptimal threshold: {opt_thresh:.4f}')\n",
                "print(f'  F1       : {opt_metrics[\"f1\"]:.4f}')\n",
                "print(f'  Precision: {opt_metrics[\"precision\"]:.4f}')\n",
                "print(f'  Recall   : {opt_metrics[\"recall\"]:.4f}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# ROC + PR curves\n",
                "from sklearn.metrics import roc_curve, precision_recall_curve, roc_auc_score, average_precision_score\n",
                "\n",
                "pal = {'LightGBM': '#2ecc71', 'XGBoost': '#3498db', 'CatBoost': '#e74c3c'}\n",
                "fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
                "\n",
                "for n, p in preds.items():\n",
                "    c = pal[n]\n",
                "    fpr, tpr, _ = roc_curve(y_test, p)\n",
                "    ax[0].plot(fpr, tpr, color=c, lw=2,\n",
                "               label=f'{n} ({roc_auc_score(y_test, p):.4f})')\n",
                "    pre, rec, _ = precision_recall_curve(y_test, p)\n",
                "    ax[1].plot(rec, pre, color=c, lw=2,\n",
                "               label=f'{n} ({average_precision_score(y_test, p):.4f})')\n",
                "\n",
                "ax[0].plot([0,1], [0,1], 'k--', alpha=0.3)\n",
                "ax[0].set(title='ROC Curve', xlabel='FPR', ylabel='TPR')\n",
                "ax[0].legend(loc='lower right')\n",
                "ax[1].set(title='Precision-Recall Curve', xlabel='Recall', ylabel='Precision')\n",
                "ax[1].legend(loc='lower left')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(f'{OUT}/roc_pr.png', dpi=200, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# Feature importance (LightGBM top 25)\n",
                "top = lgb_m.get_feature_importance(25)\n",
                "fig, ax = plt.subplots(figsize=(10, 8))\n",
                "ax.barh(top['feature'].values[::-1], top['importance'].values[::-1], color='#3498db')\n",
                "ax.set_title('LightGBM â€” Top 25 Features', fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.savefig(f'{OUT}/feature_importance.png', dpi=200, bbox_inches='tight')\n",
                "plt.show()\n",
                "top.to_csv(f'{OUT}/feature_importance.csv', index=False)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 8 Â· Summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "print('='*60 + '\\n  ðŸ“Š TRAINING SUMMARY\\n' + '='*60)\n",
                "print(f'Dataset   : {X_train.shape[0] + X_val.shape[0] + X_test.shape[0]:,} txns Ã— {len(feat_cols)} features')\n",
                "print(f'Fraud rate: ~{y_train.mean():.2%}\\n')\n",
                "print(comp.to_string(index=False))\n",
                "print(f'\\nOutputs (download from Output tab):')\n",
                "for f in sorted(os.listdir(OUT)):\n",
                "    fp = f'{OUT}/{f}'\n",
                "    if os.path.isfile(fp) and not f.startswith('.'):\n",
                "        sz = os.path.getsize(fp) / 1e6\n",
                "        print(f'  {f:40s} {sz:>7.1f} MB')\n",
                "print('\\nâœ… Download models â†’ place in local models/ â†’ run API')\n",
                "print('   uvicorn api.main:app --reload --port 8000')"
            ]
        }
    ],
    "metadata": {
        "kaggle": {
            "accelerator": "none",
            "dataSources": [
                {
                    "datasetId": "muhakabartay/yourallmodelsdata",
                    "sourceType": "datasetVersion"
                },
                {
                    "datasetId": "aryyaaaaa/fraud-detection-src",
                    "sourceType": "datasetVersion"
                }
            ],
            "isGpuEnabled": false,
            "isInternetEnabled": true,
            "language": "python",
            "sourceType": "notebook"
        },
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}